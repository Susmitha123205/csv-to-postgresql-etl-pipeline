# CSV to PostgreSQL ETL Pipeline (Python)

from pypandoc import convert_text

readme = """
# CSV to PostgreSQL ETL Pipeline (Python)

## ğŸ“Œ Project Overview
This project demonstrates a complete **end-to-end ETL (Extract, Transform, Load) pipeline** built using **Python, Pandas, and PostgreSQL**.  
It reads raw sales data from a CSV file, processes and cleans the data, and loads it into a PostgreSQL database for analysis.

This project is designed for **beginners in Data Engineering** and reflects real-world workflows.

---

## ğŸ¯ Project Goal
- Extract raw sales data from a CSV file
- Transform the data into a clean, analytics-ready format
- Load the processed data into a PostgreSQL database
- Validate the loaded data using SQL

---

## ğŸ—ï¸ Architecture

CSV File  
â†“  
Extract (Pandas)  
â†“  
Transform (Data Cleaning & Calculations)  
â†“  
Load (PostgreSQL using psycopg2)  
â†“  
Sales Table in Database

---

## ğŸ“‚ Project Structure
data-engineering-etl-project/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ raw_sales.csv
â”‚
â”œâ”€â”€ etl/
â”‚ â”œâ”€â”€ extract.py
â”‚ â”œâ”€â”€ transform.py
â”‚ â”œâ”€â”€ load.py
â”‚ â””â”€â”€ main.py
â”‚
â”œâ”€â”€ sql/
â”‚
â””â”€â”€ README.md

---

## ğŸ› ï¸ Tools & Technologies

- Python 3
- Pandas
- PostgreSQL
- psycopg2
- pgAdmin 4
- VS Code
- Windows OS

---

## ğŸ”„ ETL Process Explained

### 1ï¸âƒ£ Extract
- Reads data from `raw_sales.csv`
- Uses Pandas `read_csv()`
- Loads data into a DataFrame

### 2ï¸âƒ£ Transform
- Removes invalid or missing records
- Converts data types
- Creates a derived column:
  - `total_price = price * quantity`

### 3ï¸âƒ£ Load
- Connects Python to PostgreSQL using psycopg2
- Inserts transformed data into the `sales` table
- Commits the transaction safely

### 4ï¸âƒ£ Orchestration
- `main.py` controls the full ETL flow:
  - Extract â†’ Transform â†’ Load
  - Prints success message after execution

---

## ğŸ—„ï¸ Database Schema

**Table Name:** `sales`

| Column Name  | Data Type |
|-------------|-----------|
| order_id    | INT |
| customer    | VARCHAR(50) |
| product     | VARCHAR(50) |
| price       | INT |
| quantity    | INT |
| order_date  | DATE |
| total_price | INT |

---

## â–¶ï¸ How to Run the Project

### 1. Install Python Libraries
pip install pandas psycopg2

### 2. Start PostgreSQL
- Port: 5432
- Database: postgres

### 3. Create Table (pgAdmin)
CREATE TABLE sales (
order_id INT,
customer VARCHAR(50),
product VARCHAR(50),
price INT,
quantity INT,
order_date DATE,
total_price INT
);

### 4. Run ETL Pipeline
cd etl
python main.py

---

## âœ… Expected Output
ETL Pipeline executed successfully
## Verify:
SELECT * FROM sales;

---

## ğŸ“˜ Key Learnings

- Built a real ETL pipeline from scratch
- Integrated Python with PostgreSQL
- Handled file paths and database connections
- Validated data using SQL
- Understood real-world ETL debugging

---

## ğŸ§¾ Resume Description

Built an end-to-end ETL pipeline using Python, Pandas, and PostgreSQL to extract CSV sales data, perform data transformations, and load it into a relational database for analytics.

---

## ğŸš€ Future Improvements

- Add logging
- Use environment variables for credentials
- Handle duplicate records
- Automate pipeline execution
- Integrate with Apache Airflow

